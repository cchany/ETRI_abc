{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GPS data preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. 원본(raw) 데이터는 ETRI AIfactory 사이트에서 획득할 수 있습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">https://nanum.etri.re.kr/share/schung1/ETRILifelogDataset2020?lang=ko_KR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Installing libraries and importing packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting datatable\n",
      "  Downloading datatable-1.0.0-cp36-cp36m-manylinux_2_12_x86_64.whl (96.6 MB)\n",
      "     |████████████████████████████████| 96.6 MB 94 kB/s              \n",
      "\u001b[?25hInstalling collected packages: datatable\n",
      "Successfully installed datatable-1.0.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install datatable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting haversine\n",
      "  Downloading haversine-2.8.0-py2.py3-none-any.whl (7.7 kB)\n",
      "Installing collected packages: haversine\n",
      "Successfully installed haversine-2.8.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install haversine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 700,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting tqdm\n",
      "  Downloading tqdm-4.64.1-py2.py3-none-any.whl (78 kB)\n",
      "     |████████████████████████████████| 78 kB 1.7 MB/s             \n",
      "\u001b[?25hCollecting importlib-resources\n",
      "  Downloading importlib_resources-5.4.0-py3-none-any.whl (28 kB)\n",
      "Collecting zipp>=3.1.0\n",
      "  Downloading zipp-3.6.0-py3-none-any.whl (5.3 kB)\n",
      "Installing collected packages: zipp, importlib-resources, tqdm\n",
      "\u001b[33m  WARNING: The script tqdm is installed in '/mnt/data/tkeo12/.local/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\n",
      "Successfully installed importlib-resources-5.4.0 tqdm-4.64.1 zipp-3.6.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 950,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import datatable as dt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from haversine import haversine\n",
    "from datetime import datetime\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Generating functions for preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2-1. extractAllUserDistanceOfYear(year)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> 년도를 파라미터로 입력하면 해당년도의 모든 대상자에 대한 gps date를 numpy ndarray 형태로 반환<br>\n",
    "> 대상자 ID에 포함된 숫자, timestamp에 대하여 오름차순으로 정렬하여 반환"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 460,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extractAllUserDistanceOfYear(year) :\n",
    "    \n",
    "    if year in [2018, 2019] :\n",
    "        \n",
    "        pathYear = f'dataset_{year}'\n",
    "        userNameList = os.listdir(f'/mnt/data/tkeo12/{pathYear}/{pathYear}')\n",
    "        userNameList.sort(key = int)\n",
    "        \n",
    "        userNamePathList = list(map(lambda x : f'/mnt/data/tkeo12/{pathYear}/{pathYear}/' + x, userNameList))\n",
    "        \n",
    "    elif year == 2020 :\n",
    "        \n",
    "        pattern = \"^user[0-9]+-[0-9]+$\"\n",
    "        prog = re.compile(pattern)\n",
    "        \n",
    "        userDirList = os.listdir(f'/mnt/data/tkeo12')\n",
    "        userDirList = [i for i in userDirList if prog.search(i) != None]\n",
    "        userDirList.sort(key = lambda x : int(x[-2:]))\n",
    "        \n",
    "        userNamePathList = []\n",
    "        \n",
    "        for userDir in userDirList :\n",
    "            \n",
    "            userNameList = os.listdir(f'/mnt/data/tkeo12/{userDir}/{userDir}')\n",
    "            userNameList.sort(key = lambda x : int(x[-2:]))\n",
    "            \n",
    "            userNamePathList = userNamePathList + [f'/mnt/data/tkeo12/{userDir}/{userDir}/{userName}' for userName in userNameList]\n",
    "        \n",
    "    else :\n",
    "        \n",
    "        print(\"You should check inputed year value\")\n",
    "        \n",
    "        return\n",
    "    \n",
    "    result = np.zeros([0, 7])\n",
    "    \n",
    "    for userNamePath in userNamePathList :\n",
    "        \n",
    "        userName = userNamePath.split('/')[-1]\n",
    "        oneUserGpsData = np.zeros([0, 6])\n",
    "        \n",
    "        dayCodeList = os.listdir(f'{userNamePath}')\n",
    "        \n",
    "        pattern = \"^[0-9]+$\"\n",
    "        prog = re.compile(pattern)\n",
    "        \n",
    "        dayCodeList = [dayCode for dayCode in dayCodeList if prog.search(dayCode) != None]\n",
    "        dayCodeList.sort(key = int)\n",
    "        \n",
    "        for dayCode in dayCodeList :\n",
    "            \n",
    "            date = datetime.fromtimestamp(int(dayCode)).strftime('%Y-%m-%d')\n",
    "            oneDayGpsData = np.zeros([0, 5])\n",
    "            \n",
    "            gpsDataList = os.listdir(f'{userNamePath}/{dayCode}/mGps')\n",
    "            gpsDataList = [gpsData for gpsData in gpsDataList if gpsData[-4:] == '.csv']\n",
    "            gpsDataList.sort(key = lambda x : int(x[:-4]))\n",
    "            \n",
    "            for idx, gpsDataPath in enumerate(gpsDataList) :\n",
    "                \n",
    "                minute = datetime.fromtimestamp(int(gpsDataPath[:-4])).strftime('%H:%M:%S')\n",
    "                \n",
    "                oneMinuteGpsData = dt.fread(f'{userNamePath}/{dayCode}/mGps/{gpsDataPath}').to_numpy()\n",
    "                oneMinuteGpsData = np.hstack((np.full((oneMinuteGpsData.shape[0], 1), minute), oneMinuteGpsData))\n",
    "                \n",
    "                oneDayGpsData = np.concatenate((oneDayGpsData, oneMinuteGpsData), axis = 0)\n",
    "            \n",
    "            oneDayGpsData = np.hstack((np.full((oneDayGpsData.shape[0], 1), date), oneDayGpsData))\n",
    "            \n",
    "            oneUserGpsData = np.concatenate((oneUserGpsData, oneDayGpsData), axis = 0)\n",
    "            \n",
    "        oneUserGpsData = np.hstack((np.full((oneUserGpsData.shape[0], 1), userName), oneUserGpsData))\n",
    "        \n",
    "        result = np.concatenate((result, oneUserGpsData), axis = 0)\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2-2. joiningActivityBoolean(gpsFinal, year)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> extractAllUserDistanceOfYear 반환값과 year를 파라미터로 입력하면 해당 년도의 모든 대상자에 대하여<br>\n",
    "> data_preprocessing_1 에서 생성한 유저별 avtivity timestamp에 해당하는 timestamp에 만을 남김"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 935,
   "metadata": {},
   "outputs": [],
   "source": [
    "def joiningActivityBoolean(gpsFinal, year) :\n",
    "    \n",
    "    userNameList = np.unique(gpsFinal[:, 0])\n",
    "    \n",
    "    if year in [2018, 2019] :\n",
    "    \n",
    "        userNameList = sorted(userNameList, key = int)\n",
    "        \n",
    "    elif year == 2020 :\n",
    "        \n",
    "        userNameList = sorted(userNameList, key = lambda x : int(x[4:]))\n",
    "    \n",
    "    else :\n",
    "        \n",
    "        print(\"You should check inputed year value\")\n",
    "        \n",
    "        return\n",
    "    \n",
    "    userNameList = list(userNameList)\n",
    "    \n",
    "    result = np.zeros([0, gpsFinal.shape[1]])\n",
    "    \n",
    "    for userName in tqdm(userNameList, desc = 'userName', position = 0, leave = True) :\n",
    "        \n",
    "        userData = gpsFinal[gpsFinal[:, 0] == userName]\n",
    "\n",
    "        userArray = userData[:, [1, 2]]\n",
    "        \n",
    "        joiningValueArray1 = np.char.add(userArray[:, 0], np.char.add(' ', userArray[:, 1]))\n",
    "        \n",
    "        if year == 2018 :\n",
    "            \n",
    "            activityMinuteData = dt.fread(f'/mnt/data/tkeo12/exer{year}/user{userName.zfill(2)}_gps.csv').to_numpy()\n",
    "        \n",
    "        elif year == 2019 :\n",
    "            \n",
    "            activityMinuteData = dt.fread(f'/mnt/data/tkeo12/exer{year}/user{userName[1:]}_gps.csv').to_numpy()\n",
    "        \n",
    "        else :\n",
    "            \n",
    "            activityMinuteData = dt.fread(f'/mnt/data/tkeo12/{userName}_gps.csv').to_numpy()\n",
    "        \n",
    "        joiningValueArray2 = np.array([datetime.fromtimestamp(int(i[0])).strftime('%Y-%m-%d %H:%M:%S') for i in activityMinuteData])\n",
    "        \n",
    "        userData = userData[np.in1d(joiningValueArray1, joiningValueArray2)]\n",
    "        \n",
    "        result = np.append(result, userData, axis = 0)\n",
    "        \n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2-3. haversineApplyByUserDate_ver2(yearData, year, unit = 'm')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> extractAllUserDistanceOfYear 반환값(혹은 joiningActivityBoolean 처리 이후도 가능)과 년도를 파라미터로 넣어주면 <br>\n",
    "> 해당 년도의 모든 유저들에 대하여 gps data를 기반으로 이동거리를 haversine 방식으로 하루 단위로 산출한 numpy ndarray를 반환"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 939,
   "metadata": {},
   "outputs": [],
   "source": [
    "def haversineApplyByUserDate_ver2(yearData, year, unit = 'm') :\n",
    "\n",
    "    result = np.zeros([0, 3])\n",
    "    \n",
    "    users = np.unique(yearData[:, 0])\n",
    "    \n",
    "    if year in [2018, 2019] :\n",
    "    \n",
    "        users = sorted(users, key = int)\n",
    "        \n",
    "    elif year == 2020 :\n",
    "        \n",
    "        users = sorted(users, key = lambda x : int(x[4:]))\n",
    "    \n",
    "    else :\n",
    "        \n",
    "        print(\"You should check inputed year value\")\n",
    "        \n",
    "        return\n",
    "    \n",
    "    for user in tqdm(users, desc = 'user', position = 0, leave = False) :\n",
    "        \n",
    "        user_data = yearData[yearData[:, 0] == user]\n",
    "        dates = np.unique(user_data[:, 1])\n",
    "        \n",
    "        for date in tqdm(dates, desc = 'date', position = 0, leave = False) :\n",
    "            \n",
    "            date_data = user_data[user_data[:, 1] == date]\n",
    "            minutes = np.unique(date_data[:, 2])\n",
    "            \n",
    "            resultValue = 0\n",
    "            \n",
    "            for minute in tqdm(minutes, desc = 'minute', position = 0, leave = False) :\n",
    "                \n",
    "                minute_data = date_data[date_data[:, 2] == minute]\n",
    "                \n",
    "                haversine_input = minute_data[:, [4, 5]]\n",
    "                haversine_input = np.hstack([haversine_input[:-1], haversine_input[1:]])\n",
    "                haversine_array = np.array([haversine(i[[0, 1]], i[[2, 3]], unit) for i in haversine_input.astype(float)])\n",
    "                resultValue += np.sum(haversine_array)\n",
    "            \n",
    "            result = np.append(result, np.array([user, date, resultValue]).reshape(1, 3), axis = 0)\n",
    "            \n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Generating final activity distance array from gps data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> gps data로부터 activity distance를 유저별 하루단위로 산출하기 위한 세 가지 함수를 모두 적용하고, 산출된 array를 변수에 지정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 936,
   "metadata": {},
   "outputs": [],
   "source": [
    "a1 = extractAllUserDistanceOfYear(2018)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 937,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "userName: 100%|██████████| 29/29 [00:00<00:00, 35.95it/s]\n"
     ]
    }
   ],
   "source": [
    "b1 = joiningActivityBoolean(a1, 2018)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 940,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                     \r"
     ]
    }
   ],
   "source": [
    "c1 = haversineApplyByUserDate_ver2(b1, 2018)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1088,
   "metadata": {},
   "outputs": [],
   "source": [
    "c1[:, 0] = np.char.add('user', np.char.zfill(c1[:, 0], 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1092,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['user01', '2018-11-15', '0.0'],\n",
       "       ['user01', '2018-11-16', '0.0'],\n",
       "       ['user01', '2018-11-17', '0.0'],\n",
       "       ['user01', '2018-11-18', '0.0'],\n",
       "       ['user01', '2018-11-19', '0.0'],\n",
       "       ['user01', '2018-11-21', '0.0'],\n",
       "       ['user01', '2018-11-22', '0.0'],\n",
       "       ['user01', '2018-11-23', '0.0'],\n",
       "       ['user01', '2018-11-24', '0.0'],\n",
       "       ['user01', '2018-11-25', '0.0']], dtype='<U32')"
      ]
     },
     "execution_count": 1092,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c1[:10, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 941,
   "metadata": {},
   "outputs": [],
   "source": [
    "a2 = extractAllUserDistanceOfYear(2019)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 942,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "userName: 100%|██████████| 20/20 [00:00<00:00, 33.85it/s]\n"
     ]
    }
   ],
   "source": [
    "b2 = joiningActivityBoolean(a2, 2019)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1118,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                     \r"
     ]
    }
   ],
   "source": [
    "c2 = haversineApplyByUserDate_ver2(b2, 2019)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1133,
   "metadata": {},
   "outputs": [],
   "source": [
    "c2[:, 0] = np.array(['user' + i[1:] for i in c2[:, 0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['user01', '2020-01-01', '0.0'],\n",
       "       ['user01', '2020-01-02', '0.0'],\n",
       "       ['user01', '2020-01-03', '0.0'],\n",
       "       ['user01', '2020-01-05', '0.0'],\n",
       "       ['user01', '2020-01-06', '0.0'],\n",
       "       ['user01', '2020-01-08', '0.0'],\n",
       "       ['user01', '2020-01-09', '0.0'],\n",
       "       ['user01', '2020-01-10', '0.0'],\n",
       "       ['user01', '2020-01-12', '0.0'],\n",
       "       ['user01', '2020-01-13', '0.0']], dtype='<U32')"
      ]
     },
     "execution_count": 1136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c2[:10, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1154,
   "metadata": {},
   "outputs": [],
   "source": [
    "a3 = extractAllUserDistanceOfYear(2020)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1155,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "userName: 100%|██████████| 22/22 [00:24<00:00,  1.12s/it]\n"
     ]
    }
   ],
   "source": [
    "b3 = joiningActivityBoolean(a3, 2020)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1156,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                     \r"
     ]
    }
   ],
   "source": [
    "c3 = haversineApplyByUserDate_ver2(b3, 2020)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1157,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['user01', '2020-09-25', '1157.7430115214522'],\n",
       "       ['user03', '2020-09-13', '1518.9766046103969'],\n",
       "       ['user03', '2020-09-27', '1184.1323509402796'],\n",
       "       ['user04', '2020-08-31', '7569.131564074202'],\n",
       "       ['user04', '2020-09-01', '5214.384421606917'],\n",
       "       ['user04', '2020-09-03', '4418.739242164301'],\n",
       "       ['user04', '2020-09-05', '499.0298040056463'],\n",
       "       ['user04', '2020-09-07', '1265.359267615462'],\n",
       "       ['user04', '2020-09-10', '4868.7750492021205'],\n",
       "       ['user04', '2020-09-11', '5284.602057618277']], dtype='<U32')"
      ]
     },
     "execution_count": 1157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c3[:10, :]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Merging activity distance array to lifelog data table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> 최종 activity distance array 를 라이프로그 데이터 테이블에 병합 후 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1152,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SleepExerMaker(year) :\n",
    "    \n",
    "    if year == 2018 :\n",
    "        gpsData = 'c1'\n",
    "        Left = pd.read_csv(f'/mnt/data/tkeo12/user_sleep_{year}_exer.csv')\n",
    "    elif year == 2019 :\n",
    "        gpsData = 'c2'\n",
    "        Left = pd.read_csv(f'/mnt/data/tkeo12/user_sleep_{year}_exer.csv')\n",
    "    else :\n",
    "        gpsData = 'c3'\n",
    "        Left = pd.read_csv(f'/mnt/data/tkeo12/user_sleep_{year}_exer.csv').rename(columns = {'date_x' : 'date'})\n",
    "    \n",
    "    Right = pd.DataFrame(globals()[gpsData]).rename(columns = {0 : 'userName', 1 : 'date', 2 : 'gps_activity_distance'})\n",
    "    sleepExer = Left.merge(Right, how='left', left_on=['userId', 'date'], right_on=['userName', 'date'])\n",
    "    \n",
    "    return sleepExer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1159,
   "metadata": {},
   "outputs": [],
   "source": [
    "SleepExerMaker(2018).to_csv('/mnt/data/tkeo12/user_sleep_2018_exer1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1161,
   "metadata": {},
   "outputs": [],
   "source": [
    "SleepExerMaker(2019).to_csv('/mnt/data/tkeo12/user_sleep_2019_exer1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1162,
   "metadata": {},
   "outputs": [],
   "source": [
    "SleepExerMaker(2020).to_csv('/mnt/data/tkeo12/user_sleep_2020_exer1.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
